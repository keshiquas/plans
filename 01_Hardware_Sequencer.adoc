:toc: left
:imagesdir: images

= Hardware MIDI Sequencer


単体ハードウェアの作曲ガジェット製作案。
これを単体のハンディにするか、ベースステーションと組み合わせる形にするか、
PCとの連携ありにするかは、まだはっきりとしていない。


== 概要

仕様としてあまり定まっていない。

* 手のひらサイズ、電池駆動の作曲ガジェット
* シーケンス部とDSP部の組み合わせにより、ガジェットの構成をユーザーが自由に選択できる
* ハンディタイプでは、いつでもすぐにアイデアをメモできる。
* リズム(ドラムパターン)作成とコード進行作成で別デバイスにするべきか？
* 据え置き型のベースステーションに、ハンディガジェットをドッキング。自宅で本格的な製作の仕上げ作業を行う。ベースステーションはラックタイプを想定。
* シーケンサのエディットは、ハンディタイプによくある「あらかじめ入っているパターンをつなぎ合わせるだけ」のようなことは一切しない。作成の素片となる全てのパターンはユーザーが自身で作成し、ライブラリ化し、それらを使いドラムフレーズやコード進行を作っていく。
* 音源、ミキサ、エフェクタはDSP部。FPGAにより、これらは必要に応じて自由にカスタマイズ可能。
* 音声出力ユニットはLINE OUT、S/PDIFなど、音声入力ユニットはLINE入力、ギター(Hi-Z)入力、マイク入力など、ユーザーが自由に選択可能。
* MIDI入出力は本体に1系統、外部のベースステーションに8系統。
* ハンディの外形デザインは、手帳のような街中でも自然に使えるシックなものを想定。


== ゴールはどこにあるのか

まず初めにこの作曲ガジェットで、どういったことまで出来れば満足なのかをおおまかに決める。
やりたい事は、曲のアイディアを具現化し、意図を表現したい、という事。 +
楽譜を書いて終わりでは、具体的な音が無い。
一流の演奏家を集めてスタジオ収録ではコストが掛かりすぎる。

ジャズミュージシャンのデューク・エリントンは自分専用のジャズオーケストラを抱えており、
あるいは作曲家のワーグナーもまた、自分専用のオーケストラがあり
24時間体制でいつでも呼び出しに応じて演奏できるように待機していた。
両者の目的はひとえにアイディアが閃いたら、即座に音にして確かめることにある。

音は空気の振動であり、その要素は単純にさまざまな周波数とその振幅の大きさで全て表すことができる。
人は音楽を聞くと、各楽器の音色、フレーズ、リズム、ハーモニー、コード進行をそれぞれ
別の要素として捉えてしまうが、これらははあくまで周波数の違いであり、周波数の違いは
タイムスケールの違いであり、そのスケールの違いをまるで別の物として錯覚しているに過ぎない。
つまり本来音色やフレーズやハーモニーに境目は存在せず、ただリニアに周期や周波数の違いがあるだけとなる。
これらが別の要素に見えるのは人間の時間感覚的な錯覚でしかない。 +
だが、このことは作曲に大きく影響する。
具体的には音色とフレーズ、あるいは音色とリズムとの親和性となって現れる。
ただやみくもに作ったフレーズを適当な楽器に演奏させてもまったく美しくならず、
ある特定の音色を持った楽器に合わせたフレーズを作る必要があるということになる。 +
あるフレーズはそのある楽器でしか成立せず、他への汎用性が低いものこそが、
音楽的に価値の高いフレーズといえる。
また逆にあるフレーズを美しく響かせるにはそのフレーズに最適な音色が必要となる。
ハードな歪みを伴ったギターサウンドのリフを、女性オペラ歌手にコンサートホールで
半分のテンポで歌わせても、なにを表現したいのかは伝わらない。 +
さらに複数の楽器の音を重ねたら、その合成音色は本当に望む調和をするのか。
その合成音色に最適なハーモニーはどういったものなのか。 +
これら複雑な組み合わせの要素を限りなく探求するには、様々なフレーズや
ハーモニーを様々な楽器で奏で、最終的な音に対して望む美しさを持たせるにはどうすべきか、
多数の試行錯誤をし、経験を蓄積する必要がある。
そのためにあの二人は自分専用のオーケストラを持っていた。
二名の作曲家は、なにも特別なことはなく、全ての作曲家が当然のように
持ちうる悩みをどうにかしたいと足掻いたと言える。 +

楽曲を作るということは、サウンドを作るということと切っても切り離せない
作業となる。だが、現在の市販されているシステムではこの、
音色--フレーズ--テンポ--コード進行--空間表現
といった互いに相互作用しあい一体となるべき要素を完全に分けて担当するあまり、
全体としてまとまった楽曲を作り出すのが非常に困難になってしまっている。

とはいえ自分専用のオーケストラを所持するまでの高コストなものは我々には必要無い。
欲しい要素は音色やフレーズなど楽曲全体を一つの音として見たときにいかにまとまっているかであって、
バッサリ捨てるべき要素は、オーディオ特性的な音の良さや、
音源の発音数などのスペック、音の情報量(あるいは解像度)やS/N比、といったもの。
これらはコストばかり掛かり、かつ表現においてとくに貢献しない要素である。
逆に、音色作成の自由度や空間表現のエフェクトの自由度、あるいはフレーズ作業中でもすぐに
音色調整が出来たりなどのシームレスな操作環境などは絶対に捨ててはならない。
音色、空間表現などは、フレーズ、リズム、ハーモニーと一体であり、密接に関係する要素でもあり、
我々が表現したい要素そのものでもあるためだ。

こういった要求を満たすためには、極力一つのコンパクトなデバイスで楽曲製作に必要な機能全てを
コンパクトに一体化するのが理想的と思われる。

だが、完全に一体化した形態を固定化しても、システム構成の柔軟性がなくなる。
システム構成としては、シーケンサや音色エディット、ミキサーの設定やエフェクトの
パラメータ操作などはマイコン部で行い、
音源の発音やミックス処理、エフェクト処理等の信号処理はFPGAで行う。
マイコン部とFPGA部はそれぞれ別のユニットになっており、これを組み合わせて
最小のシステムが出来上がる。
マイコン部もFPGA部もコストとリソースのトレードオフをする形でいくつかのグレードから選択を行う。
音源やミキサー、エフェクタなどは、作る楽曲により必要となる数や種類が大きく異なる。
そのため、現在の市販品でシステムを構成する場合、作りたい曲の傾向によって
それぞれに違う機材を揃える必要があり、とても経済的に負担が掛かる。
だが、FPGAを使用することにより、都度、作りたい曲の必要に応じた音源、ミキサ、エフェクタ
などを構築出来るため、劇的に経済的負担が減り、無駄も無くなる。


== 作曲するということ、その思考プロセスと要素

いざ作曲をするにあたり、作業ディティールとしておおまかに2つの段階が想定される。

* 閃いたモチーフ(アイディア)をさっとメモしたい
* 音色、演奏データ、ミックス、マスタリングを含めた最終的な完成物の作成

このうち、さっとメモしたいという場面では特に悩ましい現状がある。
まずPCを立ち上げて、各種まわりの機材類の電源を入れて、PCに向かってソフトを立ち上げる。
ソフトでは曲の新規ファイルを作り、そのためのディレクトリを作り、使用するMIDIデバイスを選択し、
その他各種テンプレートを選択し、ようやく白紙の状態のエディト状態になる。 +

人はイメージの領域でモチーフを得ても、事務的な作業をやらされると強制的に頭が切り替わり、
その瞬間にそれまで持っていたはずのモチーフは全て吹き飛んでしまう。

結局現実的な対処法は、楽器を弾いて譜面を紙にメモするか、専用のハンディレコーダに吹き込むといったあたりとなる。 
だが、この手法では紙やハンディレコーダのデータはもう一度PCのアプリケーション上で
1から再構築していく必要があり二度手間となる。

また、閃くモチーフには、すでに製作作業に入っている曲の部分的な修正など多々ある。 +
これも厄介で、曲の製作作業の再開に至るまでにかなりの事務的作業が必要になり、
結果、当然のごとくモチーフは雲散霧消してしまう。

理想的な形は、思い立ったらすぐに編集できる即時性と、
各ディティール別の階層の編集をシームレスに行き来出来る楽曲の製作環境となる。
だが、これは従来の市販品を使ったり、一部のツールやデバイスのみを開発し差し替え
することなどで実現できる事ではない。
つまり、下位から上位まで全て包含し編集できるシステムを
新たに作らねばならない。

=== 作曲における作業階層

ここで、これまで「モチーフ」とおおざっぱに表記してきたが、より具体的な楽曲の構成要素は、
以下のような階層に分けられ、そのそれぞれにモチーフがある。
これは、上記の作業ディティールとは直行する要素となる。

以下の図は、図の上に書いてあるものがより低位の素材、図の下に行くほどより高位の素材になる。

[plantuml, 01_layer, png]
----
include::01_layer01.pu[]
----

* シンセサイザーを使用した音色の作成
* 細かいリック(フレーズ)の素片、ドラムパターンなど
** リックの場合は音律(コードやスケール)的要素と、強弱陰影アクセントなどのリズム的要素はそれぞれ別に管理、編集出来なければライブラリとして汎用的にはならない。
** ドラムパターンにおいても同様に、叩く楽器と、強弱陰影アクセントなどは分ける。
* ピッチベンドや音色変化などのアーティキュレーション(演奏表現)。リックやリズムパターンが実際に演奏される際に装飾として付与される。
* より高階にあたるコード進行、リズム(拍子)の変遷など
** これらの変遷の際には、変遷の両者を繋ぐ役割のフレーズ(フィル)が存在する。すなわちリックやリズムパターンは採用時に都度その場にふさわしい形に変えて楽曲へ組み込まれる。
** グルーブ
* さらにその上の転調や曲の構成など

つまり、これら階層のそれぞれにモチーフが思いつき、すぐにサッとメモしたい要求が存在する。
それぞれの階層は、その下に礎となるものが無ければ作れない。
よって作曲者は予め仕込みとして各自、自前のそれらを作っておきライブラリとしてすぐに呼び出せる必要がある。
このライブラリが自家製でないと自分の望む表現が出来なくなるため、根底を支える素材群としての
ライブラリの作成自由度が非常に重要となる。

市販品で、過去にいくつも自動アレンジャーや簡易の作曲デバイスなどが存在した。
しかし、すべてこの素材となるライブラリを自作出来ず、メーカーが用意したフレーズパターンを
組み合わせる事しか出来なかったため、「作曲」デバイスとしては根本から意味をなさない
ものばかりだった。


== 市販されている製品の現状、問題

=== シーケンサ(作曲用アプリケーション)

現状存在する作曲用のアプリケーションとしてのMIDIシーケンサ or DAW(DigitalAudioWorkStation)は、
その起源がスタジオで使用されていたマルチトラックレコーダの代替品としてスタートしている。
そのため基本的に「生演奏をそのまま記録する」ことが目的のツールとなっている。
つまり扱っているデータの実体は時間軸に沿った瞬間瞬間の演奏状態をサンプリングしたものであり、
性質としてはrawデータに分類される。これはMIDIであっても音声データであっても同様。
問題は市販されているアプリケーションがこういったrawデータ系しかないところにある。
このことは、画像アプリケーションに置き換えるならば、
ドットの色情報の集合体を扱うペイント系アプリは存在するが、
CADなどのような設計情報を扱うベクター系のアプリは存在しない、ということになる。

作曲という作業を俯瞰で捉えると、その大半は音の素片を組み合わせて楽曲を作る設計行為に他ならず、
設計が出来上がってから具体的な演奏を収録するのであり、
設計段階に相当する画像アプリでのベクター系が存在せず、ポッカリと空白地帯を形成しているのが現状となっている。

事実、作曲作業の根幹部分は、バンド形態の場合はコード符やセンイチと呼ばれるコード進行と主要なフレーズのみを書いたもの、オーケストラならスコアといった、原則譜面を紙に書いたものになっている。

=== シンセサイザ(音源)

市販されている音源の問題点のなかで特に大きいのがエンベロープの画一性にある。
エンベロープとは、おおまかに言うと簡易的な物理シミュレータに相当する。
このモジュールにより、音源は打鍵時に楽器に与えられるエネルギー、その放出による減衰などを
(かなり大胆に)カリカチュアライズした形で模倣する。

ただし、市販されている音源は基本的に鍵盤で演奏することを前提としているため、
大半の音源が鍵盤楽器をモデルとしたエンベロープを搭載する。
つまりどのキースイッチがONになったか、OFFになったかが演奏情報の抽象化の基本形であり、
演奏情報プロトコルにあたるMIDIもこれを前提としている。
エンベロープの動作を時系列で大まかに挙げると以下のようになる。

* 打鍵時にハンマーが弦を叩きエネルギーを与える。
* エネルギーを与えられた弦はそれを振動として保持し、空気中に音として放出する。
* 離鍵時に吸辰材が弦に触れ、音はほどなく鳴り止む。

問題は、このエンベロープ方式では最初に振動体を叩いてエネルギーを与える方式の
楽器しか演奏ニュアンスを表現できないところにある。
つまり、吹奏楽器や擦弦楽器などの様に継続的にかつ可変的にエネルギーが与えられる
楽器の演奏表現がうまく出来なく、そのため出来上がった楽曲はすべての楽器が
鍵盤演奏による表現形式しかないものに仕上がってしまうという問題が生じる。

むろん、市販されている音源全てがこういった画一的なエンベロープを持っているわけではない。
例としては、以下のような音源が挙げられる。

a. パッチモジュラーシンセ
b. 物理モデリング音源

パッチモジュラーシンセは、音源のモジュールがすべて個別に指定可能でユーザーは
自由に必要とするモジュールを選択し、結線し、自由度の高い音色作りが可能となっている。
物理モデリング方式は、演算にて物体が振動し、胴に共鳴し、音が作られる様子を
リアルタイムにシミュレートする方式で、楽器の挙動をリアルに再現できる。

モジュラーシンセは、望むモジュールが存在しなければユーザーとしては
それ以上の事は出来ない。
オシレータやフィルターのモジュール開発は熱心だが、エンベロープの開発、とりわけ
演奏表現に結びつくインターフェースの開発には乏しいものがある。

物理モデリングはヤマハが最初のモデルを製品化した後、それに続くモデルが開発されていない。
おそらくセールスがあまり振るわなかったと思われる。
登場時の汎用DSPの演算能力では、あまり高い情報量、解像度での楽器シミュレートが行えなかったため、
価格に対して、音の豊かさという点であまりパッとしなかった。
また、ミュージシャンの理解力がとても低く、この方式の重要性を見落とした事もある。
さらに、自由に音色を作れないという欠点もある。
物理モデリングの場合、その中の仮想空間に仮想の材質、形状、エネルギーの伝達を
プログラムする必要があり、それを一般のミュージシャンに開放するのは
現実的ではないため、結局、既存楽器のマウスピースや管などの断片を用意し、
ユーザーはそれをつなぎ合わせることしか出来ない。
また、スタンフォード大学とヤマハがパテントを持っており、他の企業がこの方式の音源を出す場合の
障壁となっているため、他社製品もほとんど出ていない。
結果、既に古く陳腐化してしまった中古品を希少性のため割高になったものを苦労して
入手する必要が出てくる。

実際にはこれらの方式ほどリソースを割かずとも、楽器のエネルギー伝達形態別に
シンセサイズのモジュール結線を用意すれば、それで演奏ニュアンスを表現するのに
充分と言える。
が、そういった低コストで望む表現力のある音源は今のところ存在しない。

=== 市販品の限界

登場当初のレコーダーやシーケンサは業務用の非常に高価な代物だったが、PCのコストダウンと普及により、
MIDIシーケンサやハードディスクマルチトラックレコーダなどは個人で購入可能になり一般に広く普及した。 +
市場規模は広がったがユーザー層の大多数が素人へと変わった。
企業という存在である以上利益を挙げつづけなければならないため、
一番の顧客層である一般人の利用者の欲する機能のみを追加して行かざるを得ない。
一般の利用者の大半は音楽理論を勉強せず、まっとうな作曲もしない。
出来合いのフレーズ集やアルペジエータで有り物をコラージュしてなんとなく作曲っぽい行為を行うか、
趣味の範囲のバンド活動にて既存の曲をコピーし、それを録音するために使用する、といったあたりが
おもな使用形態となる。
なまじ市場規模を広げたために、MIDIシーケンサは今後音楽アプリとして
作曲方面への進化が起こり得ない状況へと陥った。
また、プロミュージシャンであっても、その大半は何らかの楽器奏者であり自ら作曲をする人の割合は限られる。
結果的に作曲の作業性に対する需要はほぼ無く、製品にそれら機能を追加する動機も存在しない。
そもそもそういった概念すら存在しないように見受けられる。

逆説的に、本格的な作曲用のアプリやデバイスを開発することは、商売としては
ほとんど成功しないと言える。
もし、成功する可能性があるとするならば、我々が開発したアプリやデバイスをユーザーが
使うことそのものがミュージシャンとしてステータスになる場合のみである。
すなわち、「このアプリやデバイスは本格派しか使えない」という認識がDTM界隈に
広まり、根付いた場合にのみ「対外的に」成功したように見える状態となる。


